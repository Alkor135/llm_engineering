{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Добро пожаловать на ваше первое задание!\n",
    "\n",
    "Инструкции приведены ниже. Пожалуйста, попробуйте и загляните в папку с решениями, если у вас что-то не получается (или не стесняйтесь спрашивать меня!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Как раз перед тем, как мы приступим к заданию --</h2>\n",
    "            <span style=\"color:#f71;\">Я решил воспользоваться секундочкой, чтобы указать вам на эту страницу с полезными материалами по курсу. Здесь приведены ссылки на все слайды.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Пожалуйста, сохраните это в закладках, и со временем я продолжу добавлять туда больше полезных ссылок.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# ДОМАШНЕЕ ЗАДАНИЕ\n",
    "\n",
    "Доработайте проект первого дня, чтобы создать веб-страницу с открытым исходным кодом, работающую локально через Ollama, а не OpenAI\n",
    "\n",
    "Вы сможете использовать этот метод для всех последующих проектов, если предпочитаете не использовать платные API.\n",
    "\n",
    "**Преимущества:**\n",
    "1. Нет платы за API -интерфейс с открытым исходным кодом\n",
    "2. Данные не покидают ваш почтовый ящик\n",
    "\n",
    "**Недостатки:**\n",
    "1. Значительно меньшая мощность, чем у модели Frontier\n",
    "\n",
    "## Краткое описание установки Ollama\n",
    "\n",
    "Просто посетите [ollama.com](https://ollama.com) и установите!\n",
    "\n",
    "После завершения работы сервер ollama уже должен быть запущен локально.  \n",
    "Если вы посетите:  \n",
    "[http://localhost:11434 /](http://localhost:11434 /)\n",
    "\n",
    "Вы должны увидеть сообщение \"Ollama запущена`.  \n",
    "\n",
    "Если нет, откройте новый терминал (Mac) или Powershell (Windows) и введите \"ollama serve\".  \n",
    "И в другом терминале (Mac) или Powershell (Windows) введите `ollama pull llama3.2`  \n",
    "Затем попробуйте [http://localhost:11434/](http://localhost:11434/) еще раз.\n",
    "\n",
    "Если Ollama работает на вашем компьютере медленно, попробуйте использовать \"llama3.2:1b\" в качестве альтернативы. Запустите \"ollama pull llama3.2:1b\" из терминала или Powershell и измените приведенный ниже код с \"MODEL = \"llama3.2\"\" на \"MODEL = \"llama3.2:1b\"\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "# OLLAMA_API = 'http://localhost:11434/v1'\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"\n",
    "# MODEL = \"google/gemma-3-12b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Отвечай на вопросы на русском языке.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Опишите некоторые бизнес-приложения генеративного искусственного интеллекта\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Давайте просто убедимся, что модель загружена.\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генеративный искусственный интеллект (ГИИ) достигает steadily increasing levels of sophistication и производит широкий спектр приложений, которые внедряются в различных отраслях. Below перечислены некоторые бизнес-приложения ГИИ:\n",
      "\n",
      "1. **Гenerated Content**: Агентства content creation и публикации используют ГИИ для создания текстов, изображений, видео и других форм контента. Этот контент можно использовать в рекламных кампаниях, статьях, blogsах и на других онлайн-платформах.\n",
      "\n",
      "2. **Визуальное оправдание**: Системы визуального оправдения (Generative Adversarial Networks – GANs) могут создавать изображения, видео и 3D-модели с точностью, близкой к manusлом созданию. Это приложение часто используется в отраслях дизайна, аэрокосмического инжиниринга и кинотехнологий.\n",
      "\n",
      "3. **Модели распознавания гласов**: Модели распознавания гласов (Speech-to-Text) могут преобразовать аудио или видеоподходы в текст, используемый в различных приложениях, таких как виртуальные ассистенты, айфонные приложения и онлайн-порталы.\n",
      "\n",
      "4. **Гибридные модели для анализа данных**: Hybrids of machine learning and GANs могут быть использованы для анализа и предсказания поведения клиентов и событий в разных отраслях, таких как финансовые рынки, ломка данных и аналитика поведения.\n",
      "\n",
      "5. **Системы принятия решений**: Системы принятия решений (Decision Support Systems) могут использовать ГИИ для прогнозирования результатов различных вариантов действий или для выявления закономерностей в данных.\n",
      "\n",
      "6. **Продукты и дизайн**: Системы дизайна (Design Systems) используются для создания устойчивых, функциональных и эстетически приятных дизайнов. В этом контексте ГИИ может быть использовано для генерации различных дизайн решений.\n",
      "\n",
      "7. **Обмен данными между системами**: Системы обмена данными (Data Exchange Systems) могут использовать GANs для синхронизации и обмена данными между различными приложениями или системами.\n"
     ]
    }
   ],
   "source": [
    "# Если по какой-либо причине это не сработает, попробуйте 2 варианта, указанные в следующих ячейках\n",
    "# И еще раз проверьте инструкции в разделе \"Краткое описание установки Ollama\" в верхней части этой лабораторной работы\n",
    "# И если ничего из этого не сработает - свяжитесь со мной!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Представляем пакет llama\n",
    "\n",
    "А теперь мы сделаем то же самое, но используя элегантный пакет ollama на python вместо прямого HTTP-вызова.\n",
    "\n",
    "По сути, он выполняет тот же вызов, что и выше, к серверу ollama, работающему на локальном хосте:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бизнес-приложения генеративного искусственного интеллекта (ГИИ) представляют собой innovative решения, которые используют алгоритмы и методы ГИИ для решения конкретных бизнес- probsелей. Ниже есть некоторые примеры бизнес-приложений ГИИ:\n",
      "\n",
      "1. **Генерация контента**: Приложение \"Content Blossom\" generates high-quality и уникальный контент для социальных сетей, блогов и веб-сайтов с помощью его AI-алгоритма.\n",
      "2. **Дизайн и стилизация**: Приложение \"Prisma\" преобразует любые фотографии в works of art в стиле famous artists, таких как Picasso или Van Gogh, с помощью своих AI-algorithmов.\n",
      "3. **Маркетинг и реклама**: Приложение \"Reebok's Training Studio\" использует ГИИ для генерации индивидуальных рекламных кампаний для клиентов, на основе их хаббтов и предпочтений.\n",
      "4. **Анализ данных**: Приложение \"Google Cloud AI Platform\" позволяет компании генерировать predictive analytics и Insights с помощью его AI-алгоритмов для принятия обоснованных решений.\n",
      "5. **Издательство и медиа**: Приложение \"Substack\" использует ГИИ для генерации автоматизированного содержания и рассылки для писателей и журналистов, которые muốn создавать контент без необходимости в существующем editorial pipeline.\n",
      "6. **Обучение и развитие персонала**: Приложение \"Degreed\" использует ГИИ для генерации personalized learning plans и тренингов для сотрудников, с помощью его AI-алгоритмов.\n",
      "7. **Генерация кода**: Приложение \"Codex\" предлагаетAI-generate code для разработчиков, которые хотят быстрее создать приложения или решения.\n",
      "8. **Соответствие к рынку**: Приложение \"Llama\" генерирует automated social media posts и отзывы, с помощью своих AI-алгоритмов, чтобы помочь компаниям соответствовать рыночным тенденциям.\n",
      "9. **Генерация музыки**: Priложение \"Amper Music\" позволяет пользователям создавать и генерировать музыку для визуальных произведений с помощью AI-algorithms.\n",
      "10. **Продажи и распределение**: Приложение \"Shopify's Visual Merchandiser\" использует ГИИ для генерации автоматизированного продвижения и представления продукта, с помощью своих AI-алгоритмов.\n",
      "\n",
      "Эти бизнес-приложения демонстрируют, как генеративный искусственный интеллект может быть применен в различных отраслях для создания ценности и решения сложных проблем.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Альтернативный подход - использование библиотеки Opengl python для подключения к Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бизнес-приложения генеративного интеллектуального искусства (ГИИ) представляют собой innovative решения для различных отраслей и организаций. Ниже перечислены einige бизнес-приложений ГИИ:\n",
      "\n",
      "1. **Инженерная проектировка**: Применяются алгоритмы ГИИ на designing различных систем, таких как mechanical, piping, eléктрифiked илиstructural инженiring. They are used to create detailed 3D-модели и анализ performancesystemov.\n",
      "2. **Машинно-логический обследование**: Бизнес-приложение для анализа big data и выявления закономерностей, которые могут помочь в принятии разумных решений и предсказании поведения различных систем и событий.\n",
      "3. **Генерация контента**: Применяются алгоритмы ГИИ к созданию новой информации, Such as text, Images и Videos. Examples business use cases include generating product descriptions, blog posts and social media content.\n",
      "4. **Моделирование поведения**: Бизнес-приложение для modeling сложного поведения различных систем, таких как электрические сети, транспортные системы или financial markets. They provide valuable insights into these systems and enable more accurate predictions and better decision-making processes.\n",
      "5. **Безопасность и анастоматика**: Применяются алгоритмы ГИИ для выявления опасных ситуаций и атак, Such as malware detection в software и Identifying potential security threats in networks.\n",
      "6. **Аналитика данных**: Бизнес-приложение для быстрого анализа big data и revelation of valuable insights about customers, markets and products. They help organizations make better decisions and optimize their operations more efficiently.\n"
     ]
    }
   ],
   "source": [
    "# На самом деле есть альтернативный подход, который может понравиться некоторым пользователям\n",
    "# Вы можете использовать клиентскую библиотеку OpenAI на python для вызова Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Вы не понимаете, почему это работает?\n",
    "\n",
    "Это кажется странным, не так ли? Мы только что использовали код OpenAI для вызова Ollama?? Что происходит?!\n",
    "\n",
    "Вот и вся информация:\n",
    "\n",
    "Класс python \"OpenAI\" - это просто код, написанный инженерами OpenAI, который выполняет вызовы через Интернет к конечной точке.  \n",
    "\n",
    "Когда вы вызываете \"openai.chat.completions.create()\", этот код на python просто отправляет веб-запрос на следующий URL-адрес: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Подобный код известен как \"клиентская библиотека\" - это просто код-оболочка, который запускается на вашем компьютере для выполнения веб-запросов. На самом деле GPT работает в облаке OpenAI за этим API, а не на вашем компьютере!\n",
    "\n",
    "OpenAI был настолько популярен, что многие другие провайдеры искусственного интеллекта предоставляли идентичные веб-точки, так что вы могли использовать тот же подход.\n",
    "\n",
    "Итак, у Ollama есть конечная точка, работающая на вашем локальном компьютере по адресу http://localhost:11434/v1/chat/completions  \n",
    "А на второй неделе мы узнаем, что многие другие провайдеры делают то же самое, включая Gemini и DeepSeek.\n",
    "\n",
    "И тогда команде OpenAI пришла в голову отличная идея: они могут расширить свою клиентскую библиотеку, чтобы вы могли указать другой \"базовый URL\" и использовать их библиотеку для вызова любого совместимого API.\n",
    "\n",
    "Вот и все!\n",
    "\n",
    "Итак, когда вы говорите: `ollama_via_openai = Открыть(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Тогда это приведет к тем же вызовам конечной точки, но к Ollama вместо OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Также пробуем удивительную логическую модель DeepSeek\n",
    "\n",
    "Здесь мы используем версию Deep Seek-reasoner, доработанную до версии 1.5B.  \n",
    "На самом деле это версия Qwen версии 1.5B, которая была доработана с использованием синтетических данных, сгенерированных Deepseek R1.\n",
    "\n",
    "Другие размеры DeepSeek представлены [здесь](https://ollama.com/library/deepseek-r1), вплоть до полной версии с параметрами 671B, которая займет 404 ГБ вашего накопителя и будет слишком большой для большинства устройств!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling c5ad996bda6e: 100% ▕██████████████████▏  556 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to understand the key terms related to \"LMS\" in this context: neural network, attention, and transformer. Let me break it down step by step.\n",
      "\n",
      "First off, **neural network**—I've heard this term before. From what I remember, a neural network is a computational system that mimics the way biological neural networks operate. It's made up of interconnected nodes or neurons, which work together to process information. So it's like a complex system for learning patterns from data. But I'm not entirely sure about all its components and how they function.\n",
      "\n",
      "Next, **attention**. This also sounds familiar but new to me. From what I can gather, attention refers to the model or component that focuses on specific parts of the input when processing it. It's like highlighting certain important words in a sentence for better understanding. In models, especially machine learning ones, the attention mechanism helps the network focus on relevant information, which improves performance.\n",
      "\n",
      "Then there's **transformer**. This one is a bit more abstract. After checking my notes, I see that transformers are based on the Transformer model from attention mechanisms. The key points I remember include positional encodings for positions and a multi-head self-attention that captures contextual relationships between all pairs of the sequence. So it's this architecture used in tasks like neural machine translation.\n",
      "\n",
      "Putting it all together, LMS probably stands for Language Model Speech Mixing or something similar. But regardless, each part relates to processing text data through these components.\n",
      "\n",
      "Wait, am I missing anything about how these components work together? For instance, in a transformer model, attention allows the network to focus on specific parts of the input sequence. This helps in capturing long-range dependencies and understanding context better. Meanwhile, neural networks process these inputs efficiently by learning representations from raw features.\n",
      "\n",
      "I should also consider how these architectures are applied. Neural networks might learn to represent words or sentences. Transformers could be used for tasks like translation because they handle multiple domains well. Attention makes the model more flexible by focusing on important parts of the input.\n",
      "\n",
      "Hmm, I wonder if there's a role in LMS for handling multiple languages since that's what speech mixing typically involves. Maybe it integrates language modeling with attention mechanisms to focus on specific segments while considering others through speech mixture.\n",
      "\n",
      "Another thought: maybe the \"LMS\" refers to something more specific, like Large Language Model with Self-Attention or similar terminology. But given what I've looked up, maybe it's about combining these components for better processing of text data in tasks like translation, summarization, etc.\n",
      "\n",
      "I think I have a basic understanding now. Time to organize the information clearly.\n",
      "</think>\n",
      "\n",
      "The key concepts related to LMS (Language Model Speech Mixing) are as follows:\n",
      "\n",
      "1. **Neural Network**: A computational system that emulates biological neural networks. It processes data to learn patterns and make predictions or decisions, often through interconnected nodes.\n",
      "\n",
      "2. **Attention**: Focuses on the model's component that highlights specific parts of input for better understanding. It dynamically adjusts focus during processing, enhancing model performance by engaging with relevant information.\n",
      "\n",
      "3. **Transformer**: Based on the Transformer model, it processes sequences using positional encodings and multi-head self-attention. This architecture captures contextual relationships efficiently, widely used in tasks like machine learning translation due to its ability to handle multiple domains.\n",
      "\n",
      "LMS likely combines these elements, integrating neural networks, attention mechanisms, and transformers for processing text data in tasks such as speech mixing by focusing on specific segments while integrating across languages through multi-domain capabilities.\n"
     ]
    }
   ],
   "source": [
    "# Это может занять несколько минут! Затем вы увидите увлекательную графику \"размышлений\" внутри тегов <think>, за которой следуют несколько подходящих определений\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Отвечай на русском языке.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Пожалуйста, дайте определения некоторым ключевым понятиям, \"\n",
    "        \"лежащим в основе Lms: нейронная сеть, внимание и трансформер.\"}\n",
    "        ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# ТЕПЕРЬ упражнение для вас\n",
    "\n",
    "Возьмите код из первого дня и включите его сюда, чтобы создать сводный веб-сайт, который использует Llama 3.2, работающий локально, вместо OpenAI; используйте любой из вышеперечисленных подходов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Коммерческое предложение по продукту \"Белок соевый Опттема M-03 текстурированный\"\n",
      "\n",
      "## О produktе\n",
      "\n",
      "Upon просмотр езайтa https://ingredienty-razvitie.ru, я нашел следующую информацию о продукте:\n",
      "\n",
      "*   **Фасовка:** Блоки по 20г или бутылки по 50г.\n",
      "*  \n",
      "    Процент замены: не указано.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "system_prompt = \"Вы - ассистент, который пишет письма с комерческим предложением. \\\n",
    "Пиши лаконично на русском языке. \\\n",
    "Ответьте в markdown.\"\n",
    "user_prompt = \"\"\"\n",
    "    Сходи на сайт https://ingredienty-razvitie.ru и составь коммерческое предложение по продукту\n",
    "    Белок соевый Опттема M-03 текстурированный.\n",
    "    Найди на сайте информацию о продукте и добавь ее в письмо (фасовка, процент замены).\n",
    "    Найди на сайте контактную информацию и добавь ее в письмо.\n",
    "\"\"\"\n",
    "\n",
    "# Шаг 2: Составьте список сообщений\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "] # заполните это\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dce6fcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Коммерческое предложение: Белок соевый Опттема M-03 текстурированный\n",
      "\n",
      "**Уважаемые коллеги!**\n",
      "\n",
      "Предлагаем вашему вниманию высококачественный **белок соевый Опттема M-03 текстурированный** от компании \"Ингредиенты Развития\".\n",
      "\n",
      "**Преимущества:**\n",
      "\n",
      "*   **Текстура:** Идеальная замена мяса в производстве котлет, фарша и других мясных продуктов.\n",
      "*   **Состав:** 54% белка, 18% жира, 9% клетчатки, 6% золы.\n",
      "*   **Фасовка:**  Предлагается в упаковках по 25 кг.\n",
      "*   **Процент замены:** До 50% от объема мяса без потери качества продукта.\n",
      "\n",
      "**Применение:**\n",
      "\n",
      "*   Производство полуфабрикатов (котлеты, пельмени, голубцы и т.д.)\n",
      "*   Изготовление колбасных изделий\n",
      "*   Разработка вегетарианских и веганских продуктов\n",
      "\n",
      "**Цена и условия поставки:** Обсуждаются индивидуально при обращении к нашим специалистам.\n",
      "\n",
      "**Контактная информация:**\n",
      "\n",
      "*   Телефон: +7 (495) 665-08-23\n",
      "*   Email: info@ingredienty-razvitie.ru\n",
      "*   Сайт: [https://ingredienty-razvitie.ru/](https://ingredienty-razvitie.ru/)\n",
      "\n",
      "**Будем рады сотрудничеству!**\n",
      "\n",
      "---\n",
      "\n",
      "**Искренне,**\n",
      "\n",
      "Ваш ассистент.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "DEEPSEEK_API = 'http://localhost:1234/v1'\n",
    "# MODEL = \"deepseek/deepseek-r1-0528-qwen3-8b\"\n",
    "MODEL = \"google/gemma-3-12b\"\n",
    "\n",
    "\n",
    "ollama_via_openai = OpenAI(base_url=DEEPSEEK_API, api_key=MODEL)\n",
    "\n",
    "system_prompt = \"Вы - ассистент, который пишет письма с комерческим предложением. \\\n",
    "Пиши лаконично на русском языке. \\\n",
    "Ответьте в markdown.\"\n",
    "user_prompt = \"\"\"\n",
    "    Сходи на сайт https://ingredienty-razvitie.ru, переходя по ссылкам, найди информацию о продукте \n",
    "    Белок соевый Опттема M-03 текстурированныйи составь коммерческое предложение по этому продукту.\n",
    "    Найди на сайте информацию о продукте и добавь ее в письмо (фасовка, процент замены).\n",
    "    Найди на сайте контактную информацию и добавь ее в письмо.\n",
    "\"\"\"\n",
    "\n",
    "# Шаг 2: Составьте список сообщений\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "] # заполните это\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
